{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from random import randint, shuffle\n",
    "import random\n",
    "import re\n",
    "#from libvoikko import Voikko\n",
    "#import libvoikko\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "\n",
    "import libvoikko\n",
    "from libvoikko import Voikko\n",
    "\n",
    "Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\")\n",
    "\n",
    "#Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Anaconda3\\Lib\\site-packages\\libvoikko-4.3.dist-info\")\n",
    "\n",
    "v = libvoikko.Voikko(\"fi\", r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\\dict\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "written-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suomi on voittanut ensimmäisen mitalin Tokion olympialaisissa. ', 'Matti Mattsson oli 3. miesten 200 metrin rintauinnissa. Hän sai siis pronssimitalin. Samalla hän ui uuden Suomen ennätyksen.', 'Matssonin olympiapronssi on Suomen ensimmäinen uinnin olympiamitali 25 vuoteen.', 'Pohjois-Pohjanmaalla Kalajoella sammutetaan isoa metsäpaloa.', 'Paloalue on yli 300 hehtaaria. Se on suurin metsäpalo Suomessa sitten 70-luvun.', 'Palon sammuttaminen on ollut vaikeaa, sillä tuulisessa säässä palo on levinnyt latvapaloina eli puun latvasta toiseen. ', 'Pelastuslaitos sanoo, että lähialueen asukkaiden pitää varautua evakuointiin, jos palo vielä pääsee leviämään.', 'Sammutustyö jatkuu ainakin viikonlopun yli.', 'Koronatartuntojen määrä Suomessa kasvaa nopeasti. Tänään kirjattiin 765 uutta tartuntaa eli yli 100 enemmän kuin eilen. ', 'Terveysviranomaiset kertovat, että tartuntoja on nyt etenkin nuorilla aikuisilla. Tartunnat leviävät ravintoloissa, juhlissa ja erilaisissa yleisötilaisuuksissa.', 'Tartuntaketjut ovat myös kasvaneet suuremmiksi ja jäljitys on vaikempaa kuin ennen.', 'Juha Vainio -palkinto annetaan tänä vuonna Toni Wirtaselle. Wirtanen on Apulanta-yhtyeen laulaja, kitaristi ja lauluntekijä.', 'Juha Vainio -palkinto on 6000 euroa. Palkinto annetaan ansioituneille kotimaisille lauluntekijöille ja sanoittajille.', 'Palkintoperusteissa kiitetään erityisesti Toni Wirtasen tekemää laulua Valot pimeyksien reunoilla.', 'Yötön yö on päättynyt Lapissa tältä kesältä.', 'Suomen pohjoisimmassa kylässä Nuorgamissa yötön yö päättyi viime yönä. Runsas puoli tuntia puolenyön jälkeen aurinko laski hetkeksi horisontin alapuolelle. Sitä ennen aurinko laski Nuorgamissa edellisen kerran toukokuun puolivälissä.', 'Muualla Lapissa yötön yö päättyi jo aiemmin. Esimerkiksi Inarissa aurinko laski jo viime viikolla perjantaina.', 'Huomenna koko maassa tulee sade- ja ukkoskuuroja. Keski- ja Pohjois-Lapissa on poutaisempaa.', 'Lämpötila on 11 ja 21 asteen välillä.']\n"
     ]
    }
   ],
   "source": [
    "# Scrape articles from Yle\n",
    "\n",
    "yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "response=requests.get(yle_url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "yle_articles = results.findAll(text=True)\n",
    "\n",
    "#removing headlines and cleaning characters from scraped text\n",
    "h3s = results.findAll('h3')\n",
    "headlines = []\n",
    "\n",
    "for h3 in h3s:\n",
    "    temp = str(h3)\n",
    "    temp = temp.replace('<h3>', '')\n",
    "    temp = temp.replace('</h3>', '')\n",
    "    headlines.append(temp)\n",
    "    del temp\n",
    "\n",
    "unwanted_text = ['+ ', '–', '\\n', '–\\n', 'TV:n selkouutisilla on kesätauko. ', \\\n",
    "                  '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "unwanted_text = unwanted_text + headlines\n",
    "\n",
    "article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "article_list = [sent for sent in article_list if not '\\n' in sent]\n",
    "\n",
    "print(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Split into sentences\n",
    "\n",
    "num = randint(0, len(article_list)-1)\n",
    "\n",
    "sentence = article_list[num]\n",
    "\n",
    "# Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "word = tokenized_sent[num]\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = v.analyze(word)[0]\n",
    "\n",
    "word_baseform = lemmatized['BASEFORM']\n",
    "word_class = lemmatized['CLASS']\n",
    "\n",
    "print(word_baseform, word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the base form\n",
    "#word_baseform = voikko_dict[0]['BASEFORM']\n",
    "cases = []\n",
    "\n",
    "wikiurl = ''\n",
    "\n",
    "if word_class == 'teonsana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'nimisana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "elif word_class == 'laatusana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'asemosana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "else: wikiurl = 'https://fi.wiktionary.org'\n",
    "    \n",
    "# get the response in the form of html\n",
    "\n",
    "\n",
    "table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "response=requests.get(wikiurl)\n",
    "\n",
    "# parse data from the html into a beautifulsoup object\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "if wikitable is None:\n",
    "    table_contents = ''\n",
    "else: table_contents = wikitable.findAll(text=True)\n",
    "    \n",
    "unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                  'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                  'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                  'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                  'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                  'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                  'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                  'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "             'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "             'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "             'eivät olleet ']\n",
    "\n",
    "if len(table_contents) > 0:\n",
    "    cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "    cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "    cases = list(dict.fromkeys(cases))\n",
    "\n",
    "print(wikiurl)\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set options from selected word and randomly selected cases\n",
    "\n",
    "fill_in_blank = sentence.replace(' '+word, '_______')\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_2 = cases[num]\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_3 = cases[num]\n",
    "\n",
    "options = [word, option_2, option_3]\n",
    "\n",
    "options = random.sample(options, len(options))\n",
    "\n",
    "#print(sentence)\n",
    "print(fill_in_blank)\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERYTHING\n",
    "def myfunc():\n",
    "     \n",
    "    \n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    cases = []\n",
    "    \n",
    "    def get_word():\n",
    "        \n",
    "        num = randint(0, len(article_list)-1)\n",
    "\n",
    "        sentence = article_list[num]\n",
    "\n",
    "        # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "        tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "        tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "        tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "        num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "        word = tokenized_sent[num]\n",
    "\n",
    "        lemmatized = v.analyze(word)[0]\n",
    "\n",
    "        return lemmatized\n",
    "    \n",
    "    def get_cases():\n",
    "        \n",
    "        word_baseform = get_word()['BASEFORM']\n",
    "        word_class = get_word()['CLASS']\n",
    "\n",
    "        wikiurl = ''\n",
    "\n",
    "        if word_class == 'teonsana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'nimisana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "        elif word_class == 'laatusana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'asemosana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "        else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "        table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "        response=requests.get(wikiurl)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "        if wikitable is None:\n",
    "            table_contents = ''\n",
    "        else: table_contents = wikitable.findAll(text=True)\n",
    "        \n",
    "        return table_contents\n",
    "\n",
    "    unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                      'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                      'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                      'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                      'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                      'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                      'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                      'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "    negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                 'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                 'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                 'eivät olleet ']\n",
    "    \n",
    "    table_contents = find_cases()\n",
    "   \n",
    "    if len(table_contents) > 0:\n",
    "        cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "        cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "        cases = list(dict.fromkeys(cases))\n",
    "    \n",
    "        fill_in_blank = sentence.replace(' '+word+' ', '_______')\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_2 = cases[num]\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_3 = cases[num]\n",
    "\n",
    "        options = [word, option_2, option_3]\n",
    "\n",
    "        options = random.sample(options, len(options))\n",
    "        \n",
    "        print(fill_in_blank)\n",
    "        \n",
    "        return options\n",
    "    #else: return 'ERROR'\n",
    "\n",
    "\n",
    "print(myfunc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "noted-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yötön yö on päättynyt Lapissa tältä _____ .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kesillä', 'kesältä', 'kesissä']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def practice():\n",
    "\n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Split into sentences\n",
    "\n",
    "    num = randint(0, len(article_list)-1)\n",
    "\n",
    "    sentence = article_list[num]\n",
    "    \n",
    "    #print('Sent: '+ sentence)\n",
    "\n",
    "    # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "    tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "    num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "    word = tokenized_sent[num]\n",
    "    \n",
    "    fill_in_blank = sentence.replace(' '+word, ' _____ ')\n",
    "\n",
    "    #print('Word1: '+word)\n",
    "    #print(\"blank1: \"+fill_in_blank)\n",
    "\n",
    "    lemmatized = v.analyze(word)[0]\n",
    "\n",
    "    word_baseform = lemmatized['BASEFORM']\n",
    "    word_class = lemmatized['CLASS']\n",
    "\n",
    "    #print('Lemm: '+word_baseform, word_class)\n",
    "\n",
    "    #Extract the base form\n",
    "    #word_baseform = voikko_dict[0]['BASEFORM']\n",
    "    cases = []\n",
    "\n",
    "    wikiurl = ''\n",
    "\n",
    "    if word_class == 'teonsana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "    elif word_class == 'nimisana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "    elif word_class == 'laatusana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "    elif word_class == 'asemosana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "    else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "    # get the response in the form of html\n",
    "\n",
    "\n",
    "    table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "    response=requests.get(wikiurl)\n",
    "\n",
    "    # parse data from the html into a beautifulsoup object\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "    if wikitable is None:\n",
    "        table_contents = ''\n",
    "    else: table_contents = wikitable.findAll(text=True)\n",
    "\n",
    "    unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                      'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                      'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                      'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                      'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                      'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                      'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                      'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "    negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                 'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                 'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                 'eivät olleet ']\n",
    "\n",
    "    if len(table_contents) > 0:\n",
    "        cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "        cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "        cases = list(dict.fromkeys(cases))\n",
    "\n",
    "    #print(wikiurl)\n",
    "    #print(cases)\n",
    "\n",
    "    #set options from selected word and randomly selected cases\n",
    "    if len(cases) > 0:\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_2 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_3 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "        options = [word, option_2, option_3]\n",
    "\n",
    "        options = random.sample(options, len(options))\n",
    "\n",
    "        #print(\"word2: \"+word)\n",
    "        print(fill_in_blank)\n",
    "        #print(options)\n",
    "        return options\n",
    "    else: return practice()\n",
    "\n",
    "practice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-colleague",
   "metadata": {},
   "source": [
    "ERRORS\n",
    "\n",
    "pulling more than one sentence -> problem with beautiful soup\n",
    "output has wrong characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-thesis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
