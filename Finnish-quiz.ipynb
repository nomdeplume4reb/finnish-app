{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effective-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from random import randint, shuffle\n",
    "import random\n",
    "import re\n",
    "#from libvoikko import Voikko\n",
    "#import libvoikko\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "\n",
    "import libvoikko\n",
    "from libvoikko import Voikko\n",
    "\n",
    "Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\")\n",
    "\n",
    "#Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Anaconda3\\Lib\\site-packages\\libvoikko-4.3.dist-info\")\n",
    "\n",
    "v = libvoikko.Voikko(\"fi\", r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\\dict\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "written-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Radion selkouutiset tehdään joka päivä myös kesällä.', 'Ravintola- ja tapahtuma-ala haluavat, että Suomessa otetaan käyttöön koronapassi mahdollisimman pian.', 'Koronapassi on virallinen todiste siitä, että ihminen on rokotettu, sairastanut koronataudin tai juuri saanut koronatestissä negatiivisen tuloksen. Passin avulla ihminen pääsee esimerkiksi ravintolaan, teatteriin, konserttiin tai muihin yleisötilaisuuksiin. ', 'Ravintola- ja tapahtuma-ala pitävät passia hyvänä, koska silloin ravintoloita ei enää tarvitse sulkea eikä tapahtumia perua.', 'Monessa Euroopan maassa koronapassi on jo laajasti käytössä. Elinkeinoministeri Mika Lintilä sanoo, että hän alkaa edistää koronapassia myös Suomessa.', 'Suomen koronaluvut ovat korkeat myös tänään.', 'Uusia tartuntoja on yli 600 ja sairaalassa on yli 50 koronapotilasta. ', 'Mika Salminen Terveyden ja hyvinvoinnin laitokselta kertoo, että tartuntoja on nyt enemmän myös sellaisilla ihmisillä, jotka ovat saaneet jo yhden koronarokotteen.', 'Suomessa 65 prosenttia väestöstä on saanut ensimmäisen rokoteannoksen. Toisen annoksen on saanut noin 32 prosenttia.', 'Koronaan on Suomessa nyt kuollut yhteensä 982 ihmistä. Viikon aikana on raportoitu 2 uutta koronakuolemaa.', 'Bensan hinta on noussut kesän aikana.', '95E10-bensalaadun hinta on noussut noin 10 senttiä litralta. Nyt se maksaa keskimäärin 1,70 litralta.', 'Kalleinta bensaa myydään nyt Lapissa, Inarin Kaamasessa. Siellä bensalitra maksaa jo melkein 2 euroa.', 'Itä-Suomessa on ollut tänä kesänä tosi paljon matkailijoita. Matkailijat ovat suomalaisia, jotka koronan takia lomailevat kotimaassa.', 'Esimerkiksi Pohjois-Karjalassa ja Pohjois-Savossa matkailijoita on ollut niin paljon, että hotellit ovat olleet välillä ihan täynnä.', 'Hotellit kertovat, että koronan takia jo viime kesä oli vilkas, mutta tämä kesä on vielä vilkkaampi.', 'Torstaina koko maassa tulee sade- ja ukkoskuuroja. Etelärannikolla ja Keski- ja Pohjois-Lapissa on päivällä poutaisempaa.', 'Lämpötila on päivällä 18-25 astetta, Pohjois-Lapissa on viileämpää.']\n"
     ]
    }
   ],
   "source": [
    "# Scrape articles from Yle\n",
    "\n",
    "yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "response=requests.get(yle_url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "yle_articles = results.findAll(text=True)\n",
    "\n",
    "#removing headlines and cleaning characters from scraped text\n",
    "h3s = results.findAll('h3')\n",
    "headlines = []\n",
    "\n",
    "for h3 in h3s:\n",
    "    temp = str(h3)\n",
    "    temp = temp.replace('<h3>', '')\n",
    "    temp = temp.replace('</h3>', '')\n",
    "    headlines.append(temp)\n",
    "    del temp\n",
    "\n",
    "unwanted_text = ['+ ', '–', '\\n', '–\\n', 'TV:n selkouutisilla on kesätauko. ', \\\n",
    "                  '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "unwanted_text = unwanted_text + headlines\n",
    "\n",
    "article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "article_list = [sent for sent in article_list if not '\\n' in sent]\n",
    "\n",
    "print(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Split into sentences\n",
    "\n",
    "num = randint(0, len(article_list)-1)\n",
    "\n",
    "sentence = article_list[num]\n",
    "\n",
    "# Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "word = tokenized_sent[num]\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = v.analyze(word)[0]\n",
    "\n",
    "word_baseform = lemmatized['BASEFORM']\n",
    "word_class = lemmatized['CLASS']\n",
    "\n",
    "print(word_baseform, word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the base form\n",
    "#word_baseform = voikko_dict[0]['BASEFORM']\n",
    "cases = []\n",
    "\n",
    "wikiurl = ''\n",
    "\n",
    "if word_class == 'teonsana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'nimisana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "elif word_class == 'laatusana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'asemosana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "else: wikiurl = 'https://fi.wiktionary.org'\n",
    "    \n",
    "# get the response in the form of html\n",
    "\n",
    "\n",
    "table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "response=requests.get(wikiurl)\n",
    "\n",
    "# parse data from the html into a beautifulsoup object\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "if wikitable is None:\n",
    "    table_contents = ''\n",
    "else: table_contents = wikitable.findAll(text=True)\n",
    "    \n",
    "unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                  'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                  'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                  'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                  'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                  'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                  'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                  'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "             'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "             'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "             'eivät olleet ']\n",
    "\n",
    "if len(table_contents) > 0:\n",
    "    cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "    cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "    cases = list(dict.fromkeys(cases))\n",
    "\n",
    "print(wikiurl)\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set options from selected word and randomly selected cases\n",
    "\n",
    "fill_in_blank = sentence.replace(' '+word+' ', '_______')\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_2 = cases[num]\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_3 = cases[num]\n",
    "\n",
    "options = [word, option_2, option_3]\n",
    "\n",
    "options = random.sample(options, len(options))\n",
    "\n",
    "#print(sentence)\n",
    "print(fill_in_blank)\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERYTHING\n",
    "def myfunc():\n",
    "     \n",
    "    \n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    cases = []\n",
    "    \n",
    "    def get_word():\n",
    "        \n",
    "        num = randint(0, len(article_list)-1)\n",
    "\n",
    "        sentence = article_list[num]\n",
    "\n",
    "        # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "        tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "        tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "        tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "        num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "        word = tokenized_sent[num]\n",
    "\n",
    "        lemmatized = v.analyze(word)[0]\n",
    "\n",
    "        return lemmatized\n",
    "    \n",
    "    def get_cases():\n",
    "        \n",
    "        word_baseform = get_word()['BASEFORM']\n",
    "        word_class = get_word()['CLASS']\n",
    "\n",
    "        wikiurl = ''\n",
    "\n",
    "        if word_class == 'teonsana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'nimisana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "        elif word_class == 'laatusana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'asemosana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "        else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "        table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "        response=requests.get(wikiurl)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "        if wikitable is None:\n",
    "            table_contents = ''\n",
    "        else: table_contents = wikitable.findAll(text=True)\n",
    "        \n",
    "        return table_contents\n",
    "\n",
    "    unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                      'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                      'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                      'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                      'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                      'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                      'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                      'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "    negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                 'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                 'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                 'eivät olleet ']\n",
    "    \n",
    "    table_contents = find_cases()\n",
    "   \n",
    "    if len(table_contents) > 0:\n",
    "        cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "        cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "        cases = list(dict.fromkeys(cases))\n",
    "    \n",
    "        fill_in_blank = sentence.replace(' '+word+' ', '_______')\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_2 = cases[num]\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_3 = cases[num]\n",
    "\n",
    "        options = [word, option_2, option_3]\n",
    "\n",
    "        options = random.sample(options, len(options))\n",
    "        \n",
    "        print(fill_in_blank)\n",
    "        \n",
    "        return options\n",
    "    #else: return 'ERROR'\n",
    "\n",
    "\n",
    "print(myfunc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "noted-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koronapassi on virallinen todiste siitä, että ihminen on rokotettu, sairastanut koronataudin tai juuri saanut koronatestissä negatiivisen tuloksen. Passin avulla ihminen pääsee esimerkiksi ravintolaan, teatteriin, konserttiin tai muihin yleisötilaisuuksiin. \n",
      "['teattereina', 'teatteriin', 'teatteri']\n"
     ]
    }
   ],
   "source": [
    "def practice():\n",
    "\n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Split into sentences\n",
    "\n",
    "    num = randint(0, len(article_list)-1)\n",
    "\n",
    "    sentence = article_list[num]\n",
    "    \n",
    "    #print(sentence)\n",
    "\n",
    "    # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "    tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "    num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "    word = tokenized_sent[num]\n",
    "    \n",
    "    fill_in_blank = sentence.replace(' '+word+' ', ' _____ ')\n",
    "\n",
    "    #print(word)\n",
    "\n",
    "    lemmatized = v.analyze(word)[0]\n",
    "\n",
    "    word_baseform = lemmatized['BASEFORM']\n",
    "    word_class = lemmatized['CLASS']\n",
    "\n",
    "    #print(word_baseform, word_class)\n",
    "\n",
    "    #Extract the base form\n",
    "    #word_baseform = voikko_dict[0]['BASEFORM']\n",
    "    cases = []\n",
    "\n",
    "    wikiurl = ''\n",
    "\n",
    "    if word_class == 'teonsana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "    elif word_class == 'nimisana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "    elif word_class == 'laatusana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "    elif word_class == 'asemosana':\n",
    "        wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "    else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "    # get the response in the form of html\n",
    "\n",
    "\n",
    "    table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "    response=requests.get(wikiurl)\n",
    "\n",
    "    # parse data from the html into a beautifulsoup object\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "    if wikitable is None:\n",
    "        table_contents = ''\n",
    "    else: table_contents = wikitable.findAll(text=True)\n",
    "\n",
    "    unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                      'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                      'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                      'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                      'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                      'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                      'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                      'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "    negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                 'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                 'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                 'eivät olleet ']\n",
    "\n",
    "    if len(table_contents) > 0:\n",
    "        cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "        cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "        cases = list(dict.fromkeys(cases))\n",
    "\n",
    "    #print(wikiurl)\n",
    "    #print(cases)\n",
    "\n",
    "    #set options from selected word and randomly selected cases\n",
    "    if len(cases) > 0:\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_2 = cases[num]\n",
    "\n",
    "        num = randint(0, len(cases)-1)\n",
    "        option_3 = cases[num]\n",
    "\n",
    "        options = [word, option_2, option_3]\n",
    "\n",
    "        options = random.sample(options, len(options))\n",
    "\n",
    "        #print(sentence)\n",
    "        print(fill_in_blank)\n",
    "        print(options)\n",
    "        #return options\n",
    "    else: practice()\n",
    "\n",
    "practice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-colleague",
   "metadata": {},
   "source": [
    "ERRORS\n",
    "\n",
    "pulling more than one sentence -> problem with beautiful soup\n",
    "fill_in_blank matches sentence\n",
    "not outputting options\n",
    "output has wrong characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-lithuania",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
