{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from random import randint\n",
    "import re\n",
    "#from libvoikko import Voikko\n",
    "#import libvoikko\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape articles from Yle\n",
    "\n",
    "yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "response=requests.get(yle_url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "yle_articles = results.findAll(text=True)\n",
    "\n",
    "#removing headlines and cleaning characters from scraped text\n",
    "h3s = results.findAll('h3')\n",
    "headlines = []\n",
    "\n",
    "for h3 in h3s:\n",
    "    temp = str(h3)\n",
    "    temp = temp.replace('<h3>', '')\n",
    "    temp = temp.replace('</h3>', '')\n",
    "    headlines.append(temp)\n",
    "    del temp\n",
    "\n",
    "unwanted_text = ['+ ', '–', '\\n', '–\\n', 'TV:n selkouutisilla on kesätauko. ', \\\n",
    "                  '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "unwanted_text = unwanted_text + headlines\n",
    "\n",
    "article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "article_list = [sent for sent in article_list if not '\\n' in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Split into sentences\n",
    "\n",
    "num = randint(0, len(article_list)-1)\n",
    "\n",
    "sentence = article_list[num]\n",
    "\n",
    "# Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "word = tokenized_sent[num]\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize word\n",
    "Voikko.setLibrarySearchPath(\"C:/Users/rache/Downloads/Voikko/dict/5/mor-standard\")\n",
    "#Define a Voikko class for Finnish\n",
    "\n",
    "v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "#Analyze the word\n",
    "#analyze() function returns various info for the word\n",
    "\n",
    "#voikko_dict = v.analyze(word)\n",
    "\n",
    "#print(voikko_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the base form\n",
    "#word_baseform = voikko_dict[0]['BASEFORM']\n",
    "cases = []\n",
    "\n",
    "word_baseform = \"tarina\"\n",
    "word_class = 'nimisana'\n",
    "\n",
    "#word_baseform = voikko_obj[0].get('BASEFORM')\n",
    "#word_class = voikko_obj[0].get('CLASS')\n",
    "\n",
    "wikiurl = ''\n",
    "\n",
    "if word_class == 'teosana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'nimisana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "elif word_class == 'laatusana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "\n",
    "# get the response in the form of html\n",
    "\n",
    "\n",
    "table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "response=requests.get(wikiurl)\n",
    "\n",
    "# parse data from the html into a beautifulsoup object\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "table_contents = wikitable.findAll(text=True)\n",
    "\n",
    "unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                  'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                  'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                  'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                  'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                  'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                  'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                  'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "             'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "             'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "             'eivät olleet ']\n",
    "\n",
    "cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "cases = list(dict.fromkeys(cases))\n",
    "\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set options from selected word and randomly selected cases\n",
    "\n",
    "fill_in_blank = sentence.replace(word, '_______')\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_2 = cases[num]\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_3 = cases[num]\n",
    "\n",
    "#remove word from sentence\n",
    "\n",
    "print(fill_in_blank)\n",
    "print(word)\n",
    "print(option_2)\n",
    "print(option_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES if need to conjugate negative words\n",
    "negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "             'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "             'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "             'eivät olleet ']\n",
    "\n",
    "neg_indices = [cases.index(char) for char in cases if char in negatives]\n",
    "\n",
    "verb_cases = [cases[0], cases[1]+cases[2], cases[3]+cases[4]]\n",
    "\n",
    "print(verb_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_names = ['nominatiivi', 'genetiivi', 'partitiivi', 'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', 'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', 'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko']\n",
    "\n",
    "table = ['nominatiivi' , 'nominatiivi', 'tilanne', 'tilanteet', 'genetiivi', 'tilanteen', 'tilanteiden', 'tilanteitten', 'partitiivi', 'tilannetta', 'tilanteita', 'akkusatiivi', 'tilanne; tilanteen', 'tilanteet', 'sisäpaikallissijat', 'inessiivi', 'tilanteessa', 'tilanteissa', 'elatiivi', 'tilanteesta', 'tilanteista', 'illatiivi', 'tilanteeseen', 'tilanteisiin', 'ulkopaikallissijat', 'adessiivi' , 'tilanteella', 'tilanteilla', 'ablatiivi', 'tilanteelta', 'tilanteilta', 'allatiivi', '(tilanteelle)', 'tilanteille', 'sijamuodot', 'essiivi', 'tilanteena', 'tilanteina', 'translatiivi', 'tilanteeksi', 'tilanteiksi', 'abessiivi', 'tilanteetta', 'tilanteitta', 'instruktiivi', '–' , 'tilantein', 'komitatiivi', '–', 'tilanteine-', '+ omistusliite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binding-brisbane",
   "metadata": {},
   "outputs": [
    {
     "ename": "VoikkoException",
     "evalue": "Initialization of Voikko failed: No valid dictionaries were found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mVoikkoException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bfbfc13fbb9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mVoikko\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetLibrarySearchPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\rache\\Downloads\\data_science\\Finnish_app\\Voikko\\dict\\5\\mor-standard\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibvoikko\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVoikko\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"fi\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#lemmatized = lemmatizer.analyze(\"junassa\")[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\libvoikko.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language, path)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mVoikkoException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initialization of Voikko failed: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0municode_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mVoikkoException\u001b[0m: Initialization of Voikko failed: No valid dictionaries were found"
     ]
    }
   ],
   "source": [
    "import libvoikko\n",
    "from libvoikko import Voikko\n",
    "\n",
    "Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Downloads\\data_science\\Finnish_app\\Voikko\\dict\\5\\mor-standard\")\n",
    "\n",
    "v = libvoikko.Voikko(u\"fi\") \n",
    "\n",
    "#lemmatized = lemmatizer.analyze(\"junassa\")[0]\n",
    "\n",
    "#print(lemmatized['BASEFORM'])\n",
    "\n",
    "#help(Voikko)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "voikko_obj = [\n",
    "  {\n",
    "    \"BASEFORM\": \"tulla\",\n",
    "    \"CLASS\": \"teonsana\",\n",
    "    \"FSTOUTPUT\": \"[Lt][Xp]tulla[X]tule[Tt][Ap][P1][Ny][Ef]n\",\n",
    "    \"MOOD\": \"indicative\",\n",
    "    \"NEGATIVE\": \"false\",\n",
    "    \"NUMBER\": \"singular\",\n",
    "    \"PERSON\": \"1\",\n",
    "    \"STRUCTURE\": \"=ppppp\",\n",
    "    \"TENSE\": \"present_simple\",\n",
    "    \"WORDBASES\": \"+tulla(tulla)\"\n",
    "  },\n",
    "  {\n",
    "    \"BASEFORM\": \"tuli\",\n",
    "    \"CLASS\": \"nimisana\",\n",
    "    \"FSTOUTPUT\": \"[Ln][Xp]tuli[X]tul[Sg][Ny]en\",\n",
    "    \"NUMBER\": \"singular\",\n",
    "    \"SIJAMUOTO\": \"omanto\",\n",
    "    \"STRUCTURE\": \"=ppppp\",\n",
    "    \"WORDBASES\": \"+tuli(tuli)\"\n",
    "  }\n",
    "]\n",
    "\n",
    "word_baseform = voikko_obj[0].get('BASEFORM')\n",
    "\n",
    "word_class = voikko_obj[0].get('CLASS')\n",
    "\n",
    "print(word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "sanakirja = 'https://www.sanakirja.fi/finnish-english/'+word\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\rache\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "driver.get(sanakirja)\n",
    "\n",
    "test = []\n",
    "elems = driver.find_elements_by_xpath('//*[@id=\"sk-application\"]/main/ng-component/div/div[2]/ng-component/div/div[2]/div/suggestions-panel/nav/section[2]/suggestion-items/div/ul/li/a')\n",
    "for elem in elems:\n",
    "    test.append(elem.get_attribute(\"href\"))\n",
    "driver.quit()\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_baseform = 'tulla'\n",
    "word_class = 'teosana'\n",
    "\n",
    "wikiurl = ''\n",
    "\n",
    "if word_class == 'teosana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'nimisana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "elif word_class == 'laatusana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "    \n",
    "print(wikiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-mapping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
