{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effective-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from random import randint, shuffle\n",
    "import random\n",
    "import re\n",
    "#from libvoikko import Voikko\n",
    "#import libvoikko\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "\n",
    "import libvoikko\n",
    "from libvoikko import Voikko\n",
    "\n",
    "Voikko.setLibrarySearchPath(r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\")\n",
    "\n",
    "v = libvoikko.Voikko(\"fi\", r\"C:\\Users\\rache\\Downloads\\data_science\\finnish-app\\Voikko\\dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "written-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TV:n selkouutisilla on kesätauko.', 'Selkouutiset nähdään TV:ssä taas maanantaina 23.8.', 'Radion selkouutiset tehdään joka päivä myös kesällä.', 'Suomi on lähettänyt 2 virkamiestä Kabulin lentokentälle Afganistaniin.', 'Virkamiehet auttavat, kun ihmisiä haetaan Afganistanista Suomeen.', 'Asiasta kertoo ulkoministeri Pekka Haavisto.', 'Haavisto sanoo, että lähes 70 Suomen kansalaista on pyytänyt apua.', 'He haluavat Suomeen Afganistanista.', 'Suomi yrittää tuoda Suomeen myös Afganistanin Suomen lähetystön työntekijät.', 'Mielenosoituksia Afganistanissa', 'Afganistanissa on osoitettu mieltä Talibania vastaan.', 'Mediatiedot kertovat, että talibanit ovat ampuneet mielenosoittajia kohti Jalalabadin kaupungissa.', 'Ainakin 2 ihmistä on kuollut ja noin 10 ihmistä on loukkaantunut.', 'Koronaluvut', 'Suomessa on 673 uutta koronatartuntaa.', 'THL kertoo, että uusia koronakuolemia on 2.', 'Sairaalassa on nyt 106 ihmistä.', 'Heistä 29 saa tehohoitoa.', '2 viikon aikana on ollut lähes 2700 koronatartuntaa enemmän kuin 2 viikkoa aikaisemmin.', 'Kokoomus koronarokotukset', 'Oppositiopuolue kokoomus ehdottaa hallitukselle, että koronatestejä tehdään jatkossa myös apteekeissa.', 'Kokoomus haluaa, että testauspaikkoja on tulevaisuudessa enemmän kuin nyt.', 'Testien pitää kokoomuksen mielestä myös olla halvempia kuin nyt.', 'Kokoomuksen ehdotuksesta kertoo puheenjohtaja Petteri Orpo.', 'Hän puhui kokoomuksen kesäkokouksessa Seinäjoella.', 'Orpon mielestä Suomen apteekit pystyvät tekemään koronatestejä.', 'Orpo sanoo, että muualla Euroopassa koronatestejä tehdään paljon enemmän kuin Suomessa.', 'Konkurssit', 'Yrityksiä menee konkurssiin vähemmän kuin aikaisemmin.', 'Tilastokeskus kertoo, että konkursseja oli alkuvuonna 1,6 prosenttia vähemmän kuin samaan aikaan viime vuonna.', 'Varsinkin ravintoloita ja hotelleja meni konkurssiin vähemmän kuin viime vuonna.', 'Ravintoloiden ja hotellien konkurssit vähentyivät yli 16 prosenttia.', 'Maataloudessa ja rakennusalalla konkursseja oli enemmän kuin aikaisemmin.']\n"
     ]
    }
   ],
   "source": [
    "# Scrape articles from Yle\n",
    "\n",
    "yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "response=requests.get(yle_url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "yle_articles = results.findAll(text=True)\n",
    "\n",
    "#removing headlines and cleaning characters from scraped text\n",
    "h3s = results.findAll('h3')\n",
    "headlines = []\n",
    "\n",
    "for h3 in h3s:\n",
    "    temp = str(h3)\n",
    "    temp = temp.replace('<h3>', '')\n",
    "    temp = temp.replace('</h3>', '')\n",
    "    headlines.append(temp)\n",
    "    del temp\n",
    "\n",
    "unwanted_text = ['+ ', '–', '\\n', '–\\n', 'TV:n selkouutisilla on kesätauko. ', \\\n",
    "                  '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "unwanted_text = unwanted_text + headlines\n",
    "\n",
    "article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "article_list = [sent for sent in article_list if not '\\n' in sent]\n",
    "    \n",
    "article_list = [sent_tokenize(sent) for sent in article_list]\n",
    "\n",
    "article_list = [sent for sublist in article_list for sent in sublist]\n",
    "    \n",
    "article_list = [sent for sent in article_list if len(word_tokenize(sent))>1 ]\n",
    "\n",
    "print(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "environmental-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pystyvät\n"
     ]
    }
   ],
   "source": [
    "pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Split into sentences\n",
    "\n",
    "num = randint(0, len(article_list)-1)\n",
    "\n",
    "sentence = article_list[num]\n",
    "\n",
    "# Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "word = tokenized_sent[num]\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "environmental-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "lemmatized = v.analyze(word)[0]\n",
    "\n",
    "word_baseform = lemmatized['BASEFORM']\n",
    "word_class = lemmatized['CLASS']\n",
    "\n",
    "print(word_baseform, word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "flush-radius",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-b5c8f2b43477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ssä'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlemmatized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mword_baseform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlemmatized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BASEFORM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Extract the base form\n",
    "#word_baseform = voikko_dict[0]['BASEFORM']\n",
    "\n",
    "############\n",
    "word = 'ssä'\n",
    "lemmatized = v.analyze(word)[0]\n",
    "\n",
    "word_baseform = lemmatized['BASEFORM']\n",
    "word_class = lemmatized['CLASS']\n",
    "\n",
    "print(word_baseform, word_class)\n",
    "\n",
    "########\n",
    "\n",
    "cases = []\n",
    "\n",
    "wikiurl = ''\n",
    "\n",
    "if word_class == 'teonsana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'nimisana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "elif word_class == 'laatusana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "elif word_class == 'asemosana':\n",
    "    wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "else: wikiurl = 'https://fi.wiktionary.org'\n",
    "    \n",
    "# get the response in the form of html\n",
    "\n",
    "\n",
    "table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "response=requests.get(wikiurl)\n",
    "\n",
    "# parse data from the html into a beautifulsoup object\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "if wikitable is None:\n",
    "    table_contents = ''\n",
    "else: table_contents = wikitable.findAll(text=True)\n",
    "    \n",
    "unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                  'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                  'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                  'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                  'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                  'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                  'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                  'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "             'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "             'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "             'eivät olleet ']\n",
    "\n",
    "if len(table_contents) > 0:\n",
    "    cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "    \n",
    "    cases = [''.join(e for e in case if e.isalnum()) for case in cases]\n",
    "\n",
    "    cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "    cases = list(dict.fromkeys(cases))\n",
    "\n",
    "print(wikiurl)\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set options from selected word and randomly selected cases\n",
    "\n",
    "fill_in_blank = sentence.replace(' '+word, '_______')\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_2 = cases[num]\n",
    "\n",
    "num = randint(0, len(cases)-1)\n",
    "option_3 = cases[num]\n",
    "\n",
    "options = [word, option_2, option_3]\n",
    "\n",
    "options = random.sample(options, len(options))\n",
    "\n",
    "#print(sentence)\n",
    "print(fill_in_blank)\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine into function\n",
    "\n",
    "def practice():\n",
    "\n",
    "    yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "    response=requests.get(yle_url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "    yle_articles = results.findAll(text=True)\n",
    "\n",
    "    #removing headlines and cleaning characters from scraped text\n",
    "    h3s = results.findAll('h3')\n",
    "    headlines = []\n",
    "\n",
    "    for h3 in h3s:\n",
    "        temp = str(h3)\n",
    "        temp = temp.replace('<h3>', '')\n",
    "        temp = temp.replace('</h3>', '')\n",
    "        headlines.append(temp)\n",
    "        del temp\n",
    "\n",
    "    unwanted_text = ['+ ', '–', '\\n', '–\\n', 'TV:n selkouutisilla on kesätauko. ', \\\n",
    "                      '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "    unwanted_text = unwanted_text + headlines\n",
    "\n",
    "    article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "    article_list = [sent for sent in article_list if not '\\n' in sent]\n",
    "    \n",
    "    article_list = [sent_tokenize(sent) for sent in article_list]\n",
    "\n",
    "    article_list = [item for sublist in article_list for item in sublist]\n",
    "\n",
    "    print(article_list)\n",
    "\n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Split into sentences\n",
    "\n",
    "    num = randint(0, len(article_list)-1)\n",
    "\n",
    "    sentence = article_list[num]\n",
    "\n",
    "    #print('Sent: '+ sentence)\n",
    "\n",
    "    # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "    tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "\n",
    "    num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "    word = tokenized_sent[num]\n",
    "\n",
    "    fill_in_blank = sentence.replace(' '+word, ' _____ ')\n",
    "\n",
    "    #print('Word1: '+word)\n",
    "    #print(\"blank1: \"+fill_in_blank)\n",
    "\n",
    "    if len(v.analyze(word) > 0)\n",
    "        lemmatized = v.analyze(word)[0]\n",
    "\n",
    "        word_baseform = lemmatized['BASEFORM']\n",
    "        word_class = lemmatized['CLASS']\n",
    "\n",
    "        #print('Lemm: '+word_baseform, word_class)\n",
    "\n",
    "        #Extract the base form\n",
    "        #word_baseform = voikko_dict[0]['BASEFORM']\n",
    "        cases = []\n",
    "\n",
    "        wikiurl = ''\n",
    "\n",
    "        if word_class == 'teonsana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'nimisana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "        elif word_class == 'laatusana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'asemosana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "        else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "        # get the response in the form of html\n",
    "\n",
    "\n",
    "        table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "        response=requests.get(wikiurl)\n",
    "\n",
    "        # parse data from the html into a beautifulsoup object\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "        if wikitable is None:\n",
    "            table_contents = ''\n",
    "        else: table_contents = wikitable.findAll(text=True)\n",
    "\n",
    "        unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                          'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                          'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                          'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                          'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                          'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                          'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                          'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "        negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                     'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                     'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                     'eivät olleet ']\n",
    "\n",
    "        if len(table_contents) > 0:\n",
    "            cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "            cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "            cases = list(dict.fromkeys(cases))\n",
    "\n",
    "        #print(wikiurl)\n",
    "        #print(cases)\n",
    "\n",
    "        #set options from selected word and randomly selected cases\n",
    "        if len(cases) > 0:\n",
    "            num = randint(0, len(cases)-1)\n",
    "            option_2 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "            num = randint(0, len(cases)-1)\n",
    "            option_3 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "            options = [word, option_2, option_3]\n",
    "\n",
    "            options = random.sample(options, len(options))\n",
    "\n",
    "            return fill_in_blank, options, word\n",
    "        else: return practice()\n",
    "    else: return practice()\n",
    "\n",
    "practice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-capitol",
   "metadata": {},
   "source": [
    "#ERRORS\n",
    "\n",
    "- errors on loading\n",
    "- tokanizes multiple sentences at once\n",
    "- HEROKU cannot load voikko libraries\n",
    "- special characters (e.g. 44-vuotias)\n",
    "- loads incomplete sentences\n",
    "- yle_articles loads 2 arrays?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "noted-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLES_LIST:  ['TV:n selkouutisilla on kesätauko.', 'Selkouutiset nähdään TV:ssä taas maanantaina 23.8.', 'Radion selkouutiset tehdään joka päivä myös kesällä.', 'Afganistanista on haettu Suomeen nyt yhteensä 34 suomalaista, kertoo ulkoministeri Pekka Haavisto.', 'Lisäksi Afganistanista on haettu Suomeen joitakin afganistanilaisia, jotka ovat tehneet töitä Suomelle.', 'Afganistanissa on yhä joitakin kymmeniä suomalaisia.', 'Ihmiset pakenevat Afganistanista, koska tiukan islamistinen Taliban on ottanut vallan.', 'Sisäministeri, vihreiden Maria Ohisalo on sitä mieltä, että Suomen pitää ottaa lisää pakolaisia.', 'Suomi valmistautuu siihen, että Afganistanista pakenee ihmisiä.', 'Suomi on luvannut aikaisemmin ottaa eri maista 1050 niin sanottua kiintiöpakolaista.', 'Sisäministeriön uusi ehdotus on, että Suomi ottaa 2000 pakolaista.', 'Hallituspuolue vasemmistoliitto kannattaa sisäministeriön ehdotusta.', 'Oppositiopuolueet kokoomus ja perussuomalaiset vastustavat pakolaiskiintiön nostoa.', 'Perussuomalaisten mielestä afganistanilaisia pitää auttaa Afganistanin lähellä.', 'Teattereissa ja konserteissa luovutaan 2 metrin turvaväleistä.', 'Näin sanoo kulttuuriministeri Antti Kurvinen.', 'Tällä hetkellä teatterin ja konsertin katsomossa pitää olla 2 metrin turvaväli.', 'Tarkoitus on, että korona ei leviä.', 'Esitysten järjestäminen on vaikeaa muun muassa siksi, että katsomoissa pitää olla turvavälit.', 'Korona-aikana moni ihminen on muuttanut kehyskuntaan.', 'Kehyskunta on kunta, jonka vieressä on iso kaupunki.', 'Muun muassa Helsingistä, Tampereelta ja Oulusta muutetaan pienempään kuntaan.', 'Kehyskunnat ovat nyt kasvaneet paljon nopeammin kuin ennen koronaa.', 'Ihmiset muuttavat eniten Tuusulaan, Järvenpäähän ja Sipooseen.', 'Nämä kaikki ovat Helsingin lähistöllä.', 'Asukkaiden määrä kasvaa nopeasti myös Kaarinassa.', 'Kaarina on Turun lähellä.', 'Ihmiset muuttavat kehyskuntiin esimerkiksi siksi, että asunnot ovat halvempia kuin isoissa kaupungeissa.']\n",
      "SENT: Afganistanista on haettu Suomeen nyt yhteensä 34 suomalaista, kertoo ulkoministeri Pekka Haavisto.\n",
      "TOK_SENT:  ['on', 'haettu', 'nyt', 'yhteensä', 'suomalaista', 'kertoo', 'ulkoministeri']\n",
      "SENTENCE:  Afganistanista on haettu Suomeen nyt yhteensä 34 suomalaista, kertoo ulkoministeri Pekka Haavisto.\n",
      "LEMM: nyt seikkasana\n",
      "ARTICLES_LIST:  ['TV:n selkouutisilla on kesätauko.', 'Selkouutiset nähdään TV:ssä taas maanantaina 23.8.', 'Radion selkouutiset tehdään joka päivä myös kesällä.', 'Afganistanista on haettu Suomeen nyt yhteensä 34 suomalaista, kertoo ulkoministeri Pekka Haavisto.', 'Lisäksi Afganistanista on haettu Suomeen joitakin afganistanilaisia, jotka ovat tehneet töitä Suomelle.', 'Afganistanissa on yhä joitakin kymmeniä suomalaisia.', 'Ihmiset pakenevat Afganistanista, koska tiukan islamistinen Taliban on ottanut vallan.', 'Sisäministeri, vihreiden Maria Ohisalo on sitä mieltä, että Suomen pitää ottaa lisää pakolaisia.', 'Suomi valmistautuu siihen, että Afganistanista pakenee ihmisiä.', 'Suomi on luvannut aikaisemmin ottaa eri maista 1050 niin sanottua kiintiöpakolaista.', 'Sisäministeriön uusi ehdotus on, että Suomi ottaa 2000 pakolaista.', 'Hallituspuolue vasemmistoliitto kannattaa sisäministeriön ehdotusta.', 'Oppositiopuolueet kokoomus ja perussuomalaiset vastustavat pakolaiskiintiön nostoa.', 'Perussuomalaisten mielestä afganistanilaisia pitää auttaa Afganistanin lähellä.', 'Teattereissa ja konserteissa luovutaan 2 metrin turvaväleistä.', 'Näin sanoo kulttuuriministeri Antti Kurvinen.', 'Tällä hetkellä teatterin ja konsertin katsomossa pitää olla 2 metrin turvaväli.', 'Tarkoitus on, että korona ei leviä.', 'Esitysten järjestäminen on vaikeaa muun muassa siksi, että katsomoissa pitää olla turvavälit.', 'Korona-aikana moni ihminen on muuttanut kehyskuntaan.', 'Kehyskunta on kunta, jonka vieressä on iso kaupunki.', 'Muun muassa Helsingistä, Tampereelta ja Oulusta muutetaan pienempään kuntaan.', 'Kehyskunnat ovat nyt kasvaneet paljon nopeammin kuin ennen koronaa.', 'Ihmiset muuttavat eniten Tuusulaan, Järvenpäähän ja Sipooseen.', 'Nämä kaikki ovat Helsingin lähistöllä.', 'Asukkaiden määrä kasvaa nopeasti myös Kaarinassa.', 'Kaarina on Turun lähellä.', 'Ihmiset muuttavat kehyskuntiin esimerkiksi siksi, että asunnot ovat halvempia kuin isoissa kaupungeissa.']\n",
      "SENT: Ihmiset muuttavat eniten Tuusulaan, Järvenpäähän ja Sipooseen.\n",
      "TOK_SENT:  ['muuttavat', 'eniten', 'ja']\n",
      "SENTENCE:  Ihmiset muuttavat eniten Tuusulaan, Järvenpäähän ja Sipooseen.\n",
      "LEMM: muuttaa teonsana\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Ihmiset _____  eniten Tuusulaan, Järvenpäähän ja Sipooseen.',\n",
       " ['muutti', 'muuttivat', 'muuttavat'],\n",
       " 'muuttavat')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WORKING OUT ERRORS\n",
    "\n",
    "def practice():\n",
    "\n",
    "    yle_url = 'https://yle.fi/uutiset/osasto/selkouutiset/'\n",
    "\n",
    "    response=requests.get(yle_url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    results = soup.find(\"div\", {\"class\": \"text\"})\n",
    "\n",
    "    yle_articles = results.findAll(text=True)\n",
    "\n",
    "    #print('YLE_ARTICLES: ', yle_articles)\n",
    "    \n",
    "    #removing headlines and cleaning characters from scraped text\n",
    "    h3s = results.findAll('h3')\n",
    "    headlines = []\n",
    "\n",
    "    for h3 in h3s:\n",
    "        temp = str(h3)\n",
    "        temp = temp.replace('<h3>', '')\n",
    "        temp = temp.replace('</h3>', '')\n",
    "        headlines.append(temp)\n",
    "        del temp\n",
    "\n",
    "    unwanted_text = ['+ ', '–', '\\n', '–\\n', \\\n",
    "                      '(',')', ')\\n', ';', '-\"-\\n', '; ']\n",
    "\n",
    "    unwanted_text = unwanted_text + headlines\n",
    "\n",
    "    article_list = [char for char in yle_articles if char not in unwanted_text]\n",
    "\n",
    "    article_list = [sent for sent in article_list if not '\\n' in sent]\n",
    "    \n",
    "    article_list = [sent_tokenize(sent) for sent in article_list]\n",
    "\n",
    "    article_list = [sent for sublist in article_list for sent in sublist]\n",
    "    \n",
    "    article_list = [sent for sent in article_list if len(word_tokenize(sent))>1 ]\n",
    "\n",
    "    print('ARTICLES_LIST: ', article_list)\n",
    "\n",
    "    pattern = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # Split into sentences\n",
    "\n",
    "    num = randint(0, len(article_list)-1)\n",
    "\n",
    "    sentence = article_list[num]\n",
    "\n",
    "    print('SENT: '+ sentence)\n",
    "\n",
    "    # Tokenize sentence, remove punctuation, numbers, and capitalized words (to avoid proper nouns).\n",
    "\n",
    "    tokenized_sent = pattern.tokenize(sentence)\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if re.sub(r'[0-9]', '', word)]\n",
    "\n",
    "    tokenized_sent = [word for word in tokenized_sent if not word[0].isupper()]\n",
    "    \n",
    "    print('TOK_SENT: ', tokenized_sent)\n",
    "\n",
    "    num = randint(0, len(tokenized_sent)-1)\n",
    "\n",
    "    word = tokenized_sent[num]\n",
    "\n",
    "    fill_in_blank = sentence.replace(' '+word, ' _____ ')\n",
    "\n",
    "    print(\"SENTENCE: \", sentence)\n",
    "    #print(\"blank1: \"+fill_in_blank)\n",
    "    \n",
    "    if len(v.analyze(word)) > 0:\n",
    "\n",
    "        lemmatized = v.analyze(word)[0]\n",
    "\n",
    "        word_baseform = lemmatized['BASEFORM']\n",
    "        word_class = lemmatized['CLASS']\n",
    "\n",
    "        print('LEMM: '+word_baseform, word_class)\n",
    "\n",
    "        #Extract the base form\n",
    "        #word_baseform = voikko_dict[0]['BASEFORM']\n",
    "        cases = []\n",
    "\n",
    "        wikiurl = ''\n",
    "\n",
    "        if word_class == 'teonsana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Verbitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'nimisana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform + '#Taivutus'\n",
    "        elif word_class == 'laatusana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/Liite:Adjektiivitaivutus/suomi/'+ word_baseform\n",
    "        elif word_class == 'asemosana':\n",
    "            wikiurl = 'https://fi.wiktionary.org/wiki/'+ word_baseform\n",
    "        else: wikiurl = 'https://fi.wiktionary.org'\n",
    "\n",
    "        # get the response in the form of html\n",
    "\n",
    "\n",
    "        table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "\n",
    "        response=requests.get(wikiurl)\n",
    "\n",
    "        # parse data from the html into a beautifulsoup object\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        wikitable=soup.find('table',{'class':\"wikitable\"})\n",
    "\n",
    "        if wikitable is None:\n",
    "            table_contents = ''\n",
    "        else: table_contents = wikitable.findAll(text=True)\n",
    "\n",
    "        unwanted_chars = [word, '+ ', '–', '\\n', '–\\n', 'Taivutus\\n', 'sijamuoto', 'nominatiivi', 'genetiivi', 'partitiivi', \\\n",
    "                          'akkusatiivi', 'sisäpaikallissijat', 'inessiivi', 'elatiivi', 'illatiivi', 'ulkopaikallissijat', \\\n",
    "                          'adessiivi', 'ablatiivi', 'allatiivi', 'essiivi', 'translatiivi', 'abessiivi', 'instruktiivi', \\\n",
    "                          'komitatiivi', 'positiivi', 'sijamuoto', 'yksikkö', 'monikko', 'kieliopilliset sijamuodot\\n', \\\n",
    "                          'sisäpaikallissijat\\n', 'ulkopaikallissijat\\n', 'muut sijamuodot\\n', 'omistusliite', 'monikko\\n', \\\n",
    "                          'Positiivi', 'Komparatiivi', 'Superlatiivi', 'muut\\n','(',')', ')\\n', ';', 'Indikatiivi\\n', 'preesens\\n', \\\n",
    "                          'perfekti\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'persoona\\n', 'myönteinen\\n', 'kielteinen\\n', 'minä\\n', \\\n",
    "                          'sinä\\n','hän\\n','me\\n','-\"-\\n','te', 'Te\\n','he\\n','passiivi','imperfekti\\n','pluskvamperfekti\\n', '; ']\n",
    "\n",
    "        negatives = ['en ', 'olen ', 'en ole ', 'et ', 'olet ', 'et ole ', 'ei ',  'on ', 'ei ole ', 'emme ', 'olemme ', 'emme ole ',\\\n",
    "                     'ette ', 'olette ',  'ette ole ', 'ette ole ', 'eivät ', 'ovat ', 'eivät ole ', 'olin ', 'en ollut ', 'olit ', \\\n",
    "                     'et ollut ', 'oli ',  'ei ollut ', 'olimme ', 'emme olleet ', 'olitte ', 'ette olleet ', 'ette olleet ',  'olivat ', \\\n",
    "                     'eivät olleet ']\n",
    "\n",
    "        if len(table_contents) > 0:\n",
    "            cases = [char for char in table_contents if char not in unwanted_chars]\n",
    "\n",
    "            cases = [char for char in cases if char not in negatives]\n",
    "\n",
    "            cases = [''.join(e for e in case if e.isalnum()) for case in cases]\n",
    "\n",
    "            cases = list(dict.fromkeys(cases))\n",
    "\n",
    "        #set options from selected word and randomly selected cases\n",
    "        if len(cases) > 0:\n",
    "            num = randint(0, len(cases)-1)\n",
    "            option_2 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "            num = randint(0, len(cases)-1)\n",
    "            option_3 = cases[num].replace('-', '').replace('(', '').replace(')', '')\n",
    "\n",
    "            options = [word, option_2, option_3]\n",
    "\n",
    "            options = random.sample(options, len(options))\n",
    "\n",
    "            return fill_in_blank, options, word\n",
    "        else: return practice()\n",
    "    else: return practice()\n",
    "\n",
    "practice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sunrise-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERROR prone example:\n",
    "\n",
    "yle_articles_test = ['\\n', '\\n', 'TV:n selkouutisilla on kesätauko. Selkouutiset nähdään TV:ssä taas maanantaina 23.8. ', \\\n",
    "                     'Radion selkouutiset tehdään joka päivä myös kesällä.', 'Perussuomalaiset', '\\n', '\\n', '\\n', '\\n', '\\n', \\\n",
    "                     '\\n', '\\nRiikka Purra Perussuomalaisten puoluekokouksessa Seinäjoella.\\n', '\\n', \\\n",
    "                     '\\nKuva:\\nMarkku Ulander / Lehtikuva\\n', '\\n', '\\n', '\\n', \\\n",
    "                     'Perussuomalaiset-puolue on valinnut uuden puheenjohtajan. Perussuomalaisten uusi puheenjohtaja on ', \\\n",
    "                     'Riikka Purra', '. ', \\\n",
    "                     'Hän sai puoluekokouksen äänestyksessä 774 ääntä eli paljon enemmän ääniä kuin muut ehdokkaat. Toiseksi eniten ääniä sai Sakari Puisto, joka sai 252 ääntä.', \\\n",
    "                     'Perussuomalaisten uusi puheenjohtaja Riikka Purra sanoo, että hän haluaa kirkastaa puolueen linjaa maahanmuutosta. Purra sanoo, että perussuomalaisten pitää esimerkiksi kertoa paremmin, miksi puolue suhtautuu kriittisesti maahanmuuttoon. ', \\\n",
    "                     'Riikka Purra on 44-vuotias. Hän on myös perussuomalaisten kansanedustaja. ', 'Afganistan', '\\n', '\\n', \\\n",
    "                     '\\n', '\\n', '\\n', '\\n', '\\nYK:n pääsihteeri Antonio Guterres.\\n', '\\n', '\\nKuva:\\nMartial Trezzini / AOP\\n',\\\n",
    "                     '\\n', '\\n', '\\n', 'Afganistanissa taistelut kiihtyvät. Taliban-liike on vallannut lisää alueita.', \\\n",
    "                     'Lauantaina aamulla Taliban aloitti ison hyökkäyksen Mazar-i-Sharifin kaupunkiin Afganistanin pohjoisosassa. Uutistoimisto AP kertoi lauantaina päivällä, että taistelut lähestyvät myös pääkaupunkia Kabulia.',\\\n",
    "                     'YK:n pääsihteeri ', 'Antonio Guterres ', \\\n",
    "                     'pyytää, että Taliban lopettaa hyökkäykset. Guterres sanoo, että Afganistan voi suistua kaaokseen.', \\\n",
    "                     'Koronan kotitestit', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', \\\n",
    "                     '\\nKoronan kotitestipakkauksia. Testi, joka tehdään kotona, ei anna virallista tulosta.\\n', '\\n', \\\n",
    "                     '\\nKuva:\\nMinna Rosvall / Yle\\n', '\\n', '\\n', '\\n', \\\n",
    "                     'Koronaviruksen kotitestien myynti on lisääntynyt Suomessa. Kotitestejä myydään esimerkiksi ruokakaupoissa. Testit ovat loppuneet joistakin kaupoista. ', \\\n",
    "                     'Kaupat arvioivat, että koronan kotitestejä on ostettu paljon, koska koronatilanne on taas huonontunut. Ihmiset ovat myös huomanneet, että kotitestejä myydään kaupoissa. ', \\\n",
    "                     'Koronaviruksen kotitestistä ei kuitenkaan saa virallista testitulosta. ', 'Lämpö maapallolla', '\\n', '\\n', '\\n', '\\n', '\\n', \\\n",
    "                     '\\n', '\\nMyös Suomessa oli heinäkuussa kuumaa ja kuivaa. Monet kasvit kellastuivat. ', '\\n', '\\nKuva:\\nJouni Tanninen / Yle\\n',\\\n",
    "                     '\\n', '\\n', '\\n', \\\n",
    "                     'Heinäkuu oli tosi kuuma maapallolla. USA:n säätutkijat sanovat, että heinäkuu oli kuumin kuukausi, mitä maapallolla on mitattu. Mittauksia on tehty 142 vuotta.',\\\n",
    "                     'USA:n säätutkijoiden arvio eroaa eurooppalaisten tutkijoiden tuloksista. ', \\\n",
    "                     'Eurooppalaiset säätutkijat sanovat, että heinäkuu oli kolmanneksi kuumin, mitä maapallolla on mitattu.', \\\n",
    "                     'Sää', '\\n', '\\n','\\n', '\\n', '\\n', '\\n', \\\n",
    "                     '\\nSunnuntaina tulee sateita eri puolilla Suomea.\\n', \\\n",
    "                     '\\n', '\\n', '\\n', \\\n",
    "                     'Sää on sunnuntaina puolipilvin tai pilvinen. Sadetta tai sadekuuroja tulee eri puolilla maata. Paikoin on myös ukkosia. Lämpötila on 15 ja 19 asteen välillä. ','\\n'] \n",
    "\n",
    "article_list_test = ['TV:n selkouutisilla on kesätauko. Selkouutiset nähdään TV:ssä taas maanantaina 23.8. ', \\\n",
    "        'Radion selkouutiset tehdään joka päivä myös kesällä.', \\\n",
    "        'Perussuomalaiset-puolue on valinnut uuden puheenjohtajan. Perussuomalaisten uusi puheenjohtaja on ', \\\n",
    "        'Riikka Purra', '. ', \\\n",
    "        'Hän sai puoluekokouksen äänestyksessä 774 ääntä eli paljon enemmän ääniä kuin muut ehdokkaat. Toiseksi eniten ääniä sai Sakari Puisto, joka sai 252 ääntä.', \\\n",
    "        'Perussuomalaisten uusi puheenjohtaja Riikka Purra sanoo, että hän haluaa kirkastaa puolueen linjaa maahanmuutosta. Purra sanoo, että perussuomalaisten pitää esimerkiksi kertoa paremmin, miksi puolue suhtautuu kriittisesti maahanmuuttoon. ', \\\n",
    "        'Riikka Purra on 44-vuotias. Hän on myös perussuomalaisten kansanedustaja. ', \\\n",
    "        'Afganistanissa taistelut kiihtyvät. Taliban-liike on vallannut lisää alueita.', \\\n",
    "        'Lauantaina aamulla Taliban aloitti ison hyökkäyksen Mazar-i-Sharifin kaupunkiin Afganistanin pohjoisosassa. Uutistoimisto AP kertoi lauantaina päivällä, että taistelut lähestyvät myös pääkaupunkia Kabulia.', \\\n",
    "        'YK:n pääsihteeri ', 'Antonio Guterres ', 'pyytää, että Taliban lopettaa hyökkäykset. Guterres sanoo, että Afganistan voi suistua kaaokseen.', \\\n",
    "        'Koronaviruksen kotitestien myynti on lisääntynyt Suomessa. Kotitestejä myydään esimerkiksi ruokakaupoissa. Testit ovat loppuneet joistakin kaupoista. ', \\\n",
    "        'Kaupat arvioivat, että koronan kotitestejä on ostettu paljon, koska koronatilanne on taas huonontunut. Ihmiset ovat myös huomanneet, että kotitestejä myydään kaupoissa. ', \\\n",
    "        'Koronaviruksen kotitestistä ei kuitenkaan saa virallista testitulosta. ', \\\n",
    "        'Heinäkuu oli tosi kuuma maapallolla. USA:n säätutkijat sanovat, että heinäkuu oli kuumin kuukausi, mitä maapallolla on mitattu. Mittauksia on tehty 142 vuotta.', \\\n",
    "        'USA:n säätutkijoiden arvio eroaa eurooppalaisten tutkijoiden tuloksista. ', \\\n",
    "        'Eurooppalaiset säätutkijat sanovat, että heinäkuu oli kolmanneksi kuumin, mitä maapallolla on mitattu.', \\\n",
    "        'Sää on sunnuntaina puolipilvin tai pilvinen. Sadetta tai sadekuuroja tulee eri puolilla maata. Paikoin on myös ukkosia. Lämpötila on 15 ja 19 asteen välillä. ']\n",
    "\n",
    "yle_test1 = ['TV:n selkouutisilla on kesätauko.', 'Selkouutiset nähdään TV:ssä taas maanantaina 23.8.', 'Radion selkouutiset tehdään joka päivä myös kesällä.', 'Suomi on lähettänyt 2 virkamiestä Kabulin lentokentälle Afganistaniin.', 'Virkamiehet auttavat, kun ihmisiä haetaan Afganistanista Suomeen.', 'Asiasta kertoo ulkoministeri Pekka Haavisto.', 'Haavisto sanoo, että lähes 70 Suomen kansalaista on pyytänyt apua.', 'He haluavat Suomeen Afganistanista.', 'Suomi yrittää tuoda Suomeen myös Afganistanin Suomen lähetystön työntekijät.', 'Mielenosoituksia Afganistanissa', 'Afganistanissa on osoitettu mieltä Talibania vastaan.', 'Mediatiedot kertovat, että talibanit ovat ampuneet mielenosoittajia kohti Jalalabadin kaupungissa.', 'Ainakin 2 ihmistä on kuollut ja noin 10 ihmistä on loukkaantunut.', 'Koronaluvut', 'Suomessa on 673 uutta koronatartuntaa.', 'THL kertoo, että uusia koronakuolemia on 2.', 'Sairaalassa on nyt 106 ihmistä.', 'Heistä 29 saa tehohoitoa.', '2 viikon aikana on ollut lähes 2700 koronatartuntaa enemmän kuin 2 viikkoa aikaisemmin.', 'Kokoomus koronarokotukset', 'Oppositiopuolue kokoomus ehdottaa hallitukselle, että koronatestejä tehdään jatkossa myös apteekeissa.', 'Kokoomus haluaa, että testauspaikkoja on tulevaisuudessa enemmän kuin nyt.', 'Testien pitää kokoomuksen mielestä myös olla halvempia kuin nyt.', 'Kokoomuksen ehdotuksesta kertoo puheenjohtaja Petteri Orpo.', 'Hän puhui kokoomuksen kesäkokouksessa Seinäjoella.', 'Orpon mielestä Suomen apteekit pystyvät tekemään koronatestejä.', 'Orpo sanoo, että muualla Euroopassa koronatestejä tehdään paljon enemmän kuin Suomessa.', 'Konkurssit', 'Yrityksiä menee konkurssiin vähemmän kuin aikaisemmin.', 'Tilastokeskus kertoo, että konkursseja oli alkuvuonna 1,6 prosenttia vähemmän kuin samaan aikaan viime vuonna.', 'Varsinkin ravintoloita ja hotelleja meni konkurssiin vähemmän kuin viime vuonna.', 'Ravintoloiden ja hotellien konkurssit vähentyivät yli 16 prosenttia.', 'Maataloudessa ja rakennusalalla konkursseja oli enemmän kuin aikaisemmin.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "conceptual-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia', 'aika', 'kuva']\n",
      "asemosana\n"
     ]
    }
   ],
   "source": [
    "voikko_sub = {'nimisana':['asia', 'aika', 'kuva'], 'teosana':['olla', 'antaa', 'tehdä'], 'laatusana':['nopea', 'eri', 'hyvä'] }\n",
    "\n",
    "print(voikko_sub['nimisana'])\n",
    "\n",
    "print(v.analyze('minä')[0]['CLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-rainbow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
